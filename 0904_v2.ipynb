{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🔬 Ontology TTL Generator\n",
        "\n",
        "OpenAI Assistant API를 활용하여 문서를 분석하고 OWL/RDF 표준에 맞는 TTL 파일을 생성합니다.\n",
        "\n",
        "## 📋 기능\n",
        "- 파일 업로드 및 분석\n",
        "- 목차 기반 문서 구조 분석\n",
        "- OWL/RDF 표준에 맞는 TTL 파일 생성\n",
        "- 터미널 메시지로 진행 상황 확인\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 필요한 라이브러리 설치 및 임포트\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.105.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.2\n",
            "[notice] To update, run: C:\\Users\\user\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully import library\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import time\n",
        "import re\n",
        "\n",
        "# 환경 변수 로드\n",
        "load_dotenv()\n",
        "\n",
        "print(\"Successfully import library\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 유틸리티 함수들\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_status(message, status=\"INFO\"):\n",
        "    \"\"\"\n",
        "    터미널에 출력되는 상태메세지 커스텀\n",
        "    \"\"\"\n",
        "    status_colors = {\n",
        "        \"INFO\": \"\\033[94m\",      # 파란색\n",
        "        \"SUCCESS\": \"\\033[92m\",   # 초록색\n",
        "        \"WARNING\": \"\\033[93m\",   # 노란색\n",
        "        \"ERROR\": \"\\033[91m\",     # 빨간색\n",
        "        \"RESET\": \"\\033[0m\"       # 리셋\n",
        "    }\n",
        "    \n",
        "    color = status_colors.get(status, status_colors[\"INFO\"])\n",
        "    reset = status_colors[\"RESET\"]\n",
        "    \n",
        "    print(f\"{color}[{status}] {message}{reset}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_environment():\n",
        "    \"\"\"\n",
        "    환경 변수 설정 확인\n",
        "    \"\"\"\n",
        "    print_status(\"환경 변수 설정을 확인합니다...\", \"INFO\")\n",
        "    \n",
        "    api_key = os.getenv('OPENAI_API_KEY')\n",
        "    assistant_id = os.getenv('ASSISTANT_ID')\n",
        "    vector_store_id = os.getenv('VECTOR_STORE_ID')\n",
        "    \n",
        "    if not api_key:\n",
        "        print_status(\"OpenAI API 키가 설정되지 않았습니다.\", \"ERROR\")\n",
        "        return False\n",
        "    \n",
        "    if not assistant_id:\n",
        "        print_status(\"Assistant ID가 설정되지 않았습니다.\", \"ERROR\")\n",
        "        return False\n",
        "        \n",
        "    if not vector_store_id:\n",
        "        print_status(\"Vector Store ID가 설정되지 않았습니다.\", \"ERROR\")\n",
        "        return False\n",
        "    \n",
        "    print_status(\"모든 환경 변수가 올바르게 설정되었습니다.\", \"SUCCESS\")\n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_openai_client():\n",
        "    \"\"\"\n",
        "    OpenAI 클라이언트 초기화\n",
        "    \"\"\"\n",
        "    try:\n",
        "        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
        "        print_status(\"OpenAI 클라이언트가 성공적으로 초기화되었습니다.\", \"SUCCESS\")\n",
        "        return client\n",
        "    except Exception as e:\n",
        "        print_status(f\"OpenAI 클라이언트 초기화 실패: {str(e)}\", \"ERROR\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 메인 처리 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_files_simple(file_paths, prompt=None):\n",
        "    \"\"\"\n",
        "    파일들을 처리하여 TTL 파일 생성\n",
        "    \"\"\"\n",
        "    print_status(\"=== Ontology TTL Generator 시작 ===\", \"INFO\")\n",
        "    \n",
        "    # 환경 변수 확인\n",
        "    if not check_environment():\n",
        "        return False\n",
        "    \n",
        "    # OpenAI 클라이언트 초기화\n",
        "    client = initialize_openai_client()\n",
        "    if not client:\n",
        "        return False\n",
        "    \n",
        "    # 기본 프롬프트 설정\n",
        "    if not prompt:\n",
        "        prompt = \"\"\"첨부된 파일들을 분석하여 OWL/RDF 표준에 맞는 TTL 파일을 생성해주세요.\n",
        "\n",
        "                    요구사항:\n",
        "                    1. 목차를 기준으로 다른 문서들을 분석하세요\n",
        "                    2. OWL/RDF 표준에 맞는 Turtle 형식으로 작성하세요\n",
        "                    3. 적절한 네임스페이스, 클래스, 속성을 정의하세요\n",
        "                    4. 위기경보 수준별 조치사항의 구조를 반영하세요\n",
        "\n",
        "                    생성할 TTL 파일의 구조:\n",
        "                    - 기본 네임스페이스 정의\n",
        "                    - 위기경보 수준 클래스 (관심, 주의, 경계, 심각)\n",
        "                    - 각 수준별 상황, 조치목록, 조치내용 클래스\n",
        "                    - 부서별 임무와 역할 클래스\n",
        "                    - 적절한 속성과 관계 정의\"\"\"\n",
        "    \n",
        "    print_status(f\"프롬프트: {prompt[:100]}...\", \"INFO\")\n",
        "    \n",
        "    # 파일 업로드\n",
        "    uploaded_file_ids = []\n",
        "    for file_path in file_paths:\n",
        "        if os.path.exists(file_path):\n",
        "            try:\n",
        "                print_status(f\"파일 업로드 중: {file_path}\", \"INFO\")\n",
        "                \n",
        "                with open(file_path, 'rb') as file:\n",
        "                    uploaded_file = client.files.create(\n",
        "                        file=file,\n",
        "                        purpose='assistants'\n",
        "                    )\n",
        "                \n",
        "                print_status(f\"파일 업로드 완료: {uploaded_file.id}\", \"SUCCESS\")\n",
        "                \n",
        "                # Vector Store에 파일 추가\n",
        "                vector_store_id = os.getenv('VECTOR_STORE_ID')\n",
        "                client.vector_stores.files.create(\n",
        "                    vector_store_id=vector_store_id,\n",
        "                    file_id=uploaded_file.id\n",
        "                )\n",
        "                \n",
        "                print_status(f\"Vector Store에 파일 추가 완료: {uploaded_file.id}\", \"SUCCESS\")\n",
        "                uploaded_file_ids.append(uploaded_file.id)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print_status(f\"파일 업로드 중 오류 발생: {str(e)}\", \"ERROR\")\n",
        "        else:\n",
        "            print_status(f\"파일을 찾을 수 없습니다: {file_path}\", \"ERROR\")\n",
        "    \n",
        "    if not uploaded_file_ids:\n",
        "        print_status(\"업로드된 파일이 없습니다.\", \"ERROR\")\n",
        "        return False\n",
        "    \n",
        "    print_status(f\"{len(uploaded_file_ids)}개 파일이 성공적으로 업로드되었습니다.\", \"SUCCESS\")\n",
        "    \n",
        "    # Thread 생성 및 실행\n",
        "    try:\n",
        "        print_status(\"Thread를 생성합니다...\", \"INFO\")\n",
        "        thread = client.threads.create()\n",
        "        print_status(f\"Thread 생성 완료: {thread.id}\", \"SUCCESS\")\n",
        "        \n",
        "        # 메시지 추가\n",
        "        message_content = prompt + \"\\n\\n첨부된 파일들을 분석하여 TTL 파일을 생성해주세요.\"\n",
        "        print_status(\"메시지를 Thread에 추가합니다...\", \"INFO\")\n",
        "        \n",
        "        message = client.threads.messages.create(\n",
        "            thread_id=thread.id,\n",
        "            role=\"user\",\n",
        "            content=message_content,\n",
        "            attachments=[{\"file_id\": file_id, \"tools\": [{\"type\": \"file_search\"}]} \n",
        "                       for file_id in uploaded_file_ids]\n",
        "        )\n",
        "        \n",
        "        print_status(\"메시지 추가 완료\", \"SUCCESS\")\n",
        "        \n",
        "        # Assistant 실행\n",
        "        assistant_id = os.getenv('ASSISTANT_ID')\n",
        "        print_status(\"Assistant를 실행합니다...\", \"INFO\")\n",
        "        \n",
        "        run = client.threads.runs.create(\n",
        "            thread_id=thread.id,\n",
        "            assistant_id=assistant_id,\n",
        "            additional_instructions=\"목차를 기준으로 다른 문서들을 분석하여 OWL/RDF 표준에 맞는 TTL 파일을 생성해주세요. TTL 파일은 Turtle 형식으로 작성하고, 적절한 네임스페이스와 클래스, 속성을 정의해주세요.\"\n",
        "        )\n",
        "        \n",
        "        print_status(f\"Assistant 실행 시작: {run.id}\", \"SUCCESS\")\n",
        "        \n",
        "        # 실행 완료 대기\n",
        "        print_status(\"Assistant 실행 완료를 기다립니다...\", \"INFO\")\n",
        "        while True:\n",
        "            run_status = client.threads.runs.retrieve(\n",
        "                thread_id=thread.id,\n",
        "                run_id=run.id\n",
        "            )\n",
        "            \n",
        "            if run_status.status == 'completed':\n",
        "                print_status(\"Assistant 실행이 완료되었습니다.\", \"SUCCESS\")\n",
        "                break\n",
        "            elif run_status.status == 'failed':\n",
        "                print_status(\"Assistant 실행이 실패했습니다.\", \"ERROR\")\n",
        "                return False\n",
        "            elif run_status.status == 'requires_action':\n",
        "                print_status(\"Assistant가 추가 액션을 요구합니다.\", \"WARNING\")\n",
        "                return False\n",
        "            elif run_status.status == 'in_progress':\n",
        "                print_status(\"Assistant가 실행 중입니다...\", \"INFO\")\n",
        "            \n",
        "            time.sleep(2)\n",
        "        \n",
        "        # 응답 가져오기\n",
        "        print_status(\"Assistant의 응답을 가져옵니다...\", \"INFO\")\n",
        "        messages = client.threads.messages.list(\n",
        "            thread_id=thread.id,\n",
        "            order=\"desc\"\n",
        "        )\n",
        "        \n",
        "        if messages.data:\n",
        "            response = messages.data[0].content[0].text.value\n",
        "            print_status(\"응답을 성공적으로 가져왔습니다.\", \"SUCCESS\")\n",
        "            \n",
        "            # TTL 내용 추출\n",
        "            print_status(\"TTL 내용을 추출합니다...\", \"INFO\")\n",
        "            ttl_patterns = [\n",
        "                r'```ttl\\n(.*?)\\n```',\n",
        "                r'```turtle\\n(.*?)\\n```',\n",
        "                r'```\\n(.*?)\\n```'\n",
        "            ]\n",
        "            \n",
        "            ttl_content = None\n",
        "            for pattern in ttl_patterns:\n",
        "                match = re.search(pattern, response, re.DOTALL)\n",
        "                if match:\n",
        "                    ttl_content = match.group(1).strip()\n",
        "                    break\n",
        "            \n",
        "            if not ttl_content:\n",
        "                ttl_content = response.strip()\n",
        "                print_status(\"TTL 블록을 찾을 수 없어 전체 응답을 사용합니다.\", \"WARNING\")\n",
        "            else:\n",
        "                print_status(\"TTL 내용을 성공적으로 추출했습니다.\", \"SUCCESS\")\n",
        "            \n",
        "            # TTL 파일 저장\n",
        "            try:\n",
        "                with open(\"ontology.ttl\", 'w', encoding='utf-8') as f:\n",
        "                    f.write(ttl_content)\n",
        "                print_status(\"TTL 파일이 저장되었습니다: ontology.ttl\", \"SUCCESS\")\n",
        "                \n",
        "                print_status(\"=== TTL 파일 생성 완료 ===\", \"SUCCESS\")\n",
        "                print_status(\"생성된 TTL 내용:\", \"INFO\")\n",
        "                print(\"=\" * 50)\n",
        "                print(ttl_content)\n",
        "                print(\"=\" * 50)\n",
        "                return True\n",
        "                \n",
        "            except Exception as e:\n",
        "                print_status(f\"TTL 파일 저장 중 오류 발생: {str(e)}\", \"ERROR\")\n",
        "                return False\n",
        "        else:\n",
        "            print_status(\"응답을 가져올 수 없습니다.\", \"ERROR\")\n",
        "            return False\n",
        "            \n",
        "    except Exception as e:\n",
        "        print_status(f\"Thread 생성 및 실행 중 오류 발생: {str(e)}\", \"ERROR\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 로컬에 있는 3장 pdf 파일과 목차 경로 정의\n",
        "from pathlib import Path\n",
        "\n",
        "chat3_index_docs_path = Path(r\"C:\\Users\\user\\Desktop\\Project\\Ontology\\목차.txt\")\n",
        "actions_level_docs_path = Path(r\"C:\\Users\\user\\Desktop\\Project\\Ontology\\위기경보수준별조치사항.pdf\")\n",
        "docs_path = [chat3_index_docs_path, actions_level_docs_path]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m[INFO] === Ontology TTL Generator 시작 ===\u001b[0m\n",
            "\u001b[94m[INFO] 환경 변수 설정을 확인합니다...\u001b[0m\n",
            "\u001b[92m[SUCCESS] 모든 환경 변수가 올바르게 설정되었습니다.\u001b[0m\n",
            "\u001b[92m[SUCCESS] OpenAI 클라이언트가 성공적으로 초기화되었습니다.\u001b[0m\n",
            "\u001b[94m[INFO] 프롬프트: 첨부된 파일들을 분석하여 OWL/RDF 표준에 맞는 TTL 파일을 생성해주세요.\n",
            "\n",
            "                    요구사항:\n",
            "                    1. 목차를 기...\u001b[0m\n",
            "\u001b[94m[INFO] 파일 업로드 중: C:\\Users\\user\\Desktop\\Project\\Ontology\\목차.txt\u001b[0m\n",
            "\u001b[92m[SUCCESS] 파일 업로드 완료: file-T7cikFSYTXQoxjqUSduMAb\u001b[0m\n",
            "\u001b[92m[SUCCESS] Vector Store에 파일 추가 완료: file-T7cikFSYTXQoxjqUSduMAb\u001b[0m\n",
            "\u001b[94m[INFO] 파일 업로드 중: C:\\Users\\user\\Desktop\\Project\\Ontology\\위기경보수준별조치사항.pdf\u001b[0m\n",
            "\u001b[92m[SUCCESS] 파일 업로드 완료: file-C8eFEjWub2yDEbBGu3joCq\u001b[0m\n",
            "\u001b[92m[SUCCESS] Vector Store에 파일 추가 완료: file-C8eFEjWub2yDEbBGu3joCq\u001b[0m\n",
            "\u001b[92m[SUCCESS] 2개 파일이 성공적으로 업로드되었습니다.\u001b[0m\n",
            "\u001b[94m[INFO] Thread를 생성합니다...\u001b[0m\n",
            "\u001b[91m[ERROR] Thread 생성 및 실행 중 오류 발생: 'OpenAI' object has no attribute 'threads'\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "process_files_simple(docs_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
