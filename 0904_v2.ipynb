{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ”¬ Ontology TTL Generator\n",
        "\n",
        "OpenAI Assistant APIë¥¼ í™œìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  OWL/RDF í‘œì¤€ì— ë§ëŠ” TTL íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "## ğŸ“‹ ê¸°ëŠ¥\n",
        "- íŒŒì¼ ì—…ë¡œë“œ ë° ë¶„ì„\n",
        "- ëª©ì°¨ ê¸°ë°˜ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„\n",
        "- OWL/RDF í‘œì¤€ì— ë§ëŠ” TTL íŒŒì¼ ìƒì„±\n",
        "- í„°ë¯¸ë„ ë©”ì‹œì§€ë¡œ ì§„í–‰ ìƒí™© í™•ì¸\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.105.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 25.2\n",
            "[notice] To update, run: C:\\Users\\user\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully import library\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import time\n",
        "import re\n",
        "\n",
        "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
        "load_dotenv()\n",
        "\n",
        "print(\"Successfully import library\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_status(message, status=\"INFO\"):\n",
        "    \"\"\"\n",
        "    í„°ë¯¸ë„ì— ì¶œë ¥ë˜ëŠ” ìƒíƒœë©”ì„¸ì§€ ì»¤ìŠ¤í…€\n",
        "    \"\"\"\n",
        "    status_colors = {\n",
        "        \"INFO\": \"\\033[94m\",      # íŒŒë€ìƒ‰\n",
        "        \"SUCCESS\": \"\\033[92m\",   # ì´ˆë¡ìƒ‰\n",
        "        \"WARNING\": \"\\033[93m\",   # ë…¸ë€ìƒ‰\n",
        "        \"ERROR\": \"\\033[91m\",     # ë¹¨ê°„ìƒ‰\n",
        "        \"RESET\": \"\\033[0m\"       # ë¦¬ì…‹\n",
        "    }\n",
        "    \n",
        "    color = status_colors.get(status, status_colors[\"INFO\"])\n",
        "    reset = status_colors[\"RESET\"]\n",
        "    \n",
        "    print(f\"{color}[{status}] {message}{reset}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_environment():\n",
        "    \"\"\"\n",
        "    í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í™•ì¸\n",
        "    \"\"\"\n",
        "    print_status(\"í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì„ í™•ì¸í•©ë‹ˆë‹¤...\", \"INFO\")\n",
        "    \n",
        "    api_key = os.getenv('OPENAI_API_KEY')\n",
        "    assistant_id = os.getenv('ASSISTANT_ID')\n",
        "    vector_store_id = os.getenv('VECTOR_STORE_ID')\n",
        "    \n",
        "    if not api_key:\n",
        "        print_status(\"OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\", \"ERROR\")\n",
        "        return False\n",
        "    \n",
        "    if not assistant_id:\n",
        "        print_status(\"Assistant IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\", \"ERROR\")\n",
        "        return False\n",
        "        \n",
        "    if not vector_store_id:\n",
        "        print_status(\"Vector Store IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\", \"ERROR\")\n",
        "        return False\n",
        "    \n",
        "    print_status(\"ëª¨ë“  í™˜ê²½ ë³€ìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\", \"SUCCESS\")\n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_openai_client():\n",
        "    \"\"\"\n",
        "    OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "    \"\"\"\n",
        "    try:\n",
        "        client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
        "        print_status(\"OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\", \"SUCCESS\")\n",
        "        return client\n",
        "    except Exception as e:\n",
        "        print_status(f\"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}\", \"ERROR\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_files_simple(file_paths, prompt=None):\n",
        "    \"\"\"\n",
        "    íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ TTL íŒŒì¼ ìƒì„±\n",
        "    \"\"\"\n",
        "    print_status(\"=== Ontology TTL Generator ì‹œì‘ ===\", \"INFO\")\n",
        "    \n",
        "    # í™˜ê²½ ë³€ìˆ˜ í™•ì¸\n",
        "    if not check_environment():\n",
        "        return False\n",
        "    \n",
        "    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
        "    client = initialize_openai_client()\n",
        "    if not client:\n",
        "        return False\n",
        "    \n",
        "    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
        "    if not prompt:\n",
        "        prompt = \"\"\"ì²¨ë¶€ëœ íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬ OWL/RDF í‘œì¤€ì— ë§ëŠ” TTL íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "                    ìš”êµ¬ì‚¬í•­:\n",
        "                    1. ëª©ì°¨ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ë¥¸ ë¬¸ì„œë“¤ì„ ë¶„ì„í•˜ì„¸ìš”\n",
        "                    2. OWL/RDF í‘œì¤€ì— ë§ëŠ” Turtle í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”\n",
        "                    3. ì ì ˆí•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤, í´ë˜ìŠ¤, ì†ì„±ì„ ì •ì˜í•˜ì„¸ìš”\n",
        "                    4. ìœ„ê¸°ê²½ë³´ ìˆ˜ì¤€ë³„ ì¡°ì¹˜ì‚¬í•­ì˜ êµ¬ì¡°ë¥¼ ë°˜ì˜í•˜ì„¸ìš”\n",
        "\n",
        "                    ìƒì„±í•  TTL íŒŒì¼ì˜ êµ¬ì¡°:\n",
        "                    - ê¸°ë³¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜\n",
        "                    - ìœ„ê¸°ê²½ë³´ ìˆ˜ì¤€ í´ë˜ìŠ¤ (ê´€ì‹¬, ì£¼ì˜, ê²½ê³„, ì‹¬ê°)\n",
        "                    - ê° ìˆ˜ì¤€ë³„ ìƒí™©, ì¡°ì¹˜ëª©ë¡, ì¡°ì¹˜ë‚´ìš© í´ë˜ìŠ¤\n",
        "                    - ë¶€ì„œë³„ ì„ë¬´ì™€ ì—­í•  í´ë˜ìŠ¤\n",
        "                    - ì ì ˆí•œ ì†ì„±ê³¼ ê´€ê³„ ì •ì˜\"\"\"\n",
        "    \n",
        "    print_status(f\"í”„ë¡¬í”„íŠ¸: {prompt[:100]}...\", \"INFO\")\n",
        "    \n",
        "    # íŒŒì¼ ì—…ë¡œë“œ\n",
        "    uploaded_file_ids = []\n",
        "    for file_path in file_paths:\n",
        "        if os.path.exists(file_path):\n",
        "            try:\n",
        "                print_status(f\"íŒŒì¼ ì—…ë¡œë“œ ì¤‘: {file_path}\", \"INFO\")\n",
        "                \n",
        "                with open(file_path, 'rb') as file:\n",
        "                    uploaded_file = client.files.create(\n",
        "                        file=file,\n",
        "                        purpose='assistants'\n",
        "                    )\n",
        "                \n",
        "                print_status(f\"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.id}\", \"SUCCESS\")\n",
        "                \n",
        "                # Vector Storeì— íŒŒì¼ ì¶”ê°€\n",
        "                vector_store_id = os.getenv('VECTOR_STORE_ID')\n",
        "                client.vector_stores.files.create(\n",
        "                    vector_store_id=vector_store_id,\n",
        "                    file_id=uploaded_file.id\n",
        "                )\n",
        "                \n",
        "                print_status(f\"Vector Storeì— íŒŒì¼ ì¶”ê°€ ì™„ë£Œ: {uploaded_file.id}\", \"SUCCESS\")\n",
        "                uploaded_file_ids.append(uploaded_file.id)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print_status(f\"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\", \"ERROR\")\n",
        "        else:\n",
        "            print_status(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\", \"ERROR\")\n",
        "    \n",
        "    if not uploaded_file_ids:\n",
        "        print_status(\"ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\", \"ERROR\")\n",
        "        return False\n",
        "    \n",
        "    print_status(f\"{len(uploaded_file_ids)}ê°œ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\", \"SUCCESS\")\n",
        "    \n",
        "    # Thread ìƒì„± ë° ì‹¤í–‰\n",
        "    try:\n",
        "        print_status(\"Threadë¥¼ ìƒì„±í•©ë‹ˆë‹¤...\", \"INFO\")\n",
        "        thread = client.threads.create()\n",
        "        print_status(f\"Thread ìƒì„± ì™„ë£Œ: {thread.id}\", \"SUCCESS\")\n",
        "        \n",
        "        # ë©”ì‹œì§€ ì¶”ê°€\n",
        "        message_content = prompt + \"\\n\\nì²¨ë¶€ëœ íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬ TTL íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\"\n",
        "        print_status(\"ë©”ì‹œì§€ë¥¼ Threadì— ì¶”ê°€í•©ë‹ˆë‹¤...\", \"INFO\")\n",
        "        \n",
        "        message = client.threads.messages.create(\n",
        "            thread_id=thread.id,\n",
        "            role=\"user\",\n",
        "            content=message_content,\n",
        "            attachments=[{\"file_id\": file_id, \"tools\": [{\"type\": \"file_search\"}]} \n",
        "                       for file_id in uploaded_file_ids]\n",
        "        )\n",
        "        \n",
        "        print_status(\"ë©”ì‹œì§€ ì¶”ê°€ ì™„ë£Œ\", \"SUCCESS\")\n",
        "        \n",
        "        # Assistant ì‹¤í–‰\n",
        "        assistant_id = os.getenv('ASSISTANT_ID')\n",
        "        print_status(\"Assistantë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...\", \"INFO\")\n",
        "        \n",
        "        run = client.threads.runs.create(\n",
        "            thread_id=thread.id,\n",
        "            assistant_id=assistant_id,\n",
        "            additional_instructions=\"ëª©ì°¨ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ë¥¸ ë¬¸ì„œë“¤ì„ ë¶„ì„í•˜ì—¬ OWL/RDF í‘œì¤€ì— ë§ëŠ” TTL íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”. TTL íŒŒì¼ì€ Turtle í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ê³ , ì ì ˆí•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì™€ í´ë˜ìŠ¤, ì†ì„±ì„ ì •ì˜í•´ì£¼ì„¸ìš”.\"\n",
        "        )\n",
        "        \n",
        "        print_status(f\"Assistant ì‹¤í–‰ ì‹œì‘: {run.id}\", \"SUCCESS\")\n",
        "        \n",
        "        # ì‹¤í–‰ ì™„ë£Œ ëŒ€ê¸°\n",
        "        print_status(\"Assistant ì‹¤í–‰ ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦½ë‹ˆë‹¤...\", \"INFO\")\n",
        "        while True:\n",
        "            run_status = client.threads.runs.retrieve(\n",
        "                thread_id=thread.id,\n",
        "                run_id=run.id\n",
        "            )\n",
        "            \n",
        "            if run_status.status == 'completed':\n",
        "                print_status(\"Assistant ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\", \"SUCCESS\")\n",
        "                break\n",
        "            elif run_status.status == 'failed':\n",
        "                print_status(\"Assistant ì‹¤í–‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\", \"ERROR\")\n",
        "                return False\n",
        "            elif run_status.status == 'requires_action':\n",
        "                print_status(\"Assistantê°€ ì¶”ê°€ ì•¡ì…˜ì„ ìš”êµ¬í•©ë‹ˆë‹¤.\", \"WARNING\")\n",
        "                return False\n",
        "            elif run_status.status == 'in_progress':\n",
        "                print_status(\"Assistantê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤...\", \"INFO\")\n",
        "            \n",
        "            time.sleep(2)\n",
        "        \n",
        "        # ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°\n",
        "        print_status(\"Assistantì˜ ì‘ë‹µì„ ê°€ì ¸ì˜µë‹ˆë‹¤...\", \"INFO\")\n",
        "        messages = client.threads.messages.list(\n",
        "            thread_id=thread.id,\n",
        "            order=\"desc\"\n",
        "        )\n",
        "        \n",
        "        if messages.data:\n",
        "            response = messages.data[0].content[0].text.value\n",
        "            print_status(\"ì‘ë‹µì„ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\", \"SUCCESS\")\n",
        "            \n",
        "            # TTL ë‚´ìš© ì¶”ì¶œ\n",
        "            print_status(\"TTL ë‚´ìš©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤...\", \"INFO\")\n",
        "            ttl_patterns = [\n",
        "                r'```ttl\\n(.*?)\\n```',\n",
        "                r'```turtle\\n(.*?)\\n```',\n",
        "                r'```\\n(.*?)\\n```'\n",
        "            ]\n",
        "            \n",
        "            ttl_content = None\n",
        "            for pattern in ttl_patterns:\n",
        "                match = re.search(pattern, response, re.DOTALL)\n",
        "                if match:\n",
        "                    ttl_content = match.group(1).strip()\n",
        "                    break\n",
        "            \n",
        "            if not ttl_content:\n",
        "                ttl_content = response.strip()\n",
        "                print_status(\"TTL ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì „ì²´ ì‘ë‹µì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\", \"WARNING\")\n",
        "            else:\n",
        "                print_status(\"TTL ë‚´ìš©ì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.\", \"SUCCESS\")\n",
        "            \n",
        "            # TTL íŒŒì¼ ì €ì¥\n",
        "            try:\n",
        "                with open(\"ontology.ttl\", 'w', encoding='utf-8') as f:\n",
        "                    f.write(ttl_content)\n",
        "                print_status(\"TTL íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ontology.ttl\", \"SUCCESS\")\n",
        "                \n",
        "                print_status(\"=== TTL íŒŒì¼ ìƒì„± ì™„ë£Œ ===\", \"SUCCESS\")\n",
        "                print_status(\"ìƒì„±ëœ TTL ë‚´ìš©:\", \"INFO\")\n",
        "                print(\"=\" * 50)\n",
        "                print(ttl_content)\n",
        "                print(\"=\" * 50)\n",
        "                return True\n",
        "                \n",
        "            except Exception as e:\n",
        "                print_status(f\"TTL íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\", \"ERROR\")\n",
        "                return False\n",
        "        else:\n",
        "            print_status(\"ì‘ë‹µì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\", \"ERROR\")\n",
        "            return False\n",
        "            \n",
        "    except Exception as e:\n",
        "        print_status(f\"Thread ìƒì„± ë° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\", \"ERROR\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ë¡œì»¬ì— ìˆëŠ” 3ì¥ pdf íŒŒì¼ê³¼ ëª©ì°¨ ê²½ë¡œ ì •ì˜\n",
        "from pathlib import Path\n",
        "\n",
        "chat3_index_docs_path = Path(r\"C:\\Users\\user\\Desktop\\Project\\Ontology\\ëª©ì°¨.txt\")\n",
        "actions_level_docs_path = Path(r\"C:\\Users\\user\\Desktop\\Project\\Ontology\\ìœ„ê¸°ê²½ë³´ìˆ˜ì¤€ë³„ì¡°ì¹˜ì‚¬í•­.pdf\")\n",
        "docs_path = [chat3_index_docs_path, actions_level_docs_path]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m[INFO] === Ontology TTL Generator ì‹œì‘ ===\u001b[0m\n",
            "\u001b[94m[INFO] í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì„ í™•ì¸í•©ë‹ˆë‹¤...\u001b[0m\n",
            "\u001b[92m[SUCCESS] ëª¨ë“  í™˜ê²½ ë³€ìˆ˜ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\u001b[0m\n",
            "\u001b[92m[SUCCESS] OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\u001b[0m\n",
            "\u001b[94m[INFO] í”„ë¡¬í”„íŠ¸: ì²¨ë¶€ëœ íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬ OWL/RDF í‘œì¤€ì— ë§ëŠ” TTL íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\n",
            "\n",
            "                    ìš”êµ¬ì‚¬í•­:\n",
            "                    1. ëª©ì°¨ë¥¼ ê¸°...\u001b[0m\n",
            "\u001b[94m[INFO] íŒŒì¼ ì—…ë¡œë“œ ì¤‘: C:\\Users\\user\\Desktop\\Project\\Ontology\\ëª©ì°¨.txt\u001b[0m\n",
            "\u001b[92m[SUCCESS] íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: file-T7cikFSYTXQoxjqUSduMAb\u001b[0m\n",
            "\u001b[92m[SUCCESS] Vector Storeì— íŒŒì¼ ì¶”ê°€ ì™„ë£Œ: file-T7cikFSYTXQoxjqUSduMAb\u001b[0m\n",
            "\u001b[94m[INFO] íŒŒì¼ ì—…ë¡œë“œ ì¤‘: C:\\Users\\user\\Desktop\\Project\\Ontology\\ìœ„ê¸°ê²½ë³´ìˆ˜ì¤€ë³„ì¡°ì¹˜ì‚¬í•­.pdf\u001b[0m\n",
            "\u001b[92m[SUCCESS] íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: file-C8eFEjWub2yDEbBGu3joCq\u001b[0m\n",
            "\u001b[92m[SUCCESS] Vector Storeì— íŒŒì¼ ì¶”ê°€ ì™„ë£Œ: file-C8eFEjWub2yDEbBGu3joCq\u001b[0m\n",
            "\u001b[92m[SUCCESS] 2ê°œ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\u001b[0m\n",
            "\u001b[94m[INFO] Threadë¥¼ ìƒì„±í•©ë‹ˆë‹¤...\u001b[0m\n",
            "\u001b[91m[ERROR] Thread ìƒì„± ë° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: 'OpenAI' object has no attribute 'threads'\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "process_files_simple(docs_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
